<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AutoHotkey —— 自动热键软件</title>
    <url>/LanBlog/AutoHotkey1.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>

<p><b><a href="https://autohotkey.com/">AutoHotkey</a></b>是一款windows 平台下的热键脚本语言程序。可以实现诸如窗口置顶、快速输入、快捷操作等丰富多彩的功能。</p>
<span id="more"></span>

<blockquote>
<p>以下全部建立在2.0.19版本的的基础上</p>
</blockquote>
<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><ul>
<li>进入官网下载并安装<span class = "inline-note" title ="我的建议是下在c盘"><a href="https://autohotkey.com/">AutoHotkey</a></span></li>
<li>编写脚本并已 <strong>.ahk</strong> 为后缀名</li>
<li>双击脚本，即可运行</li>
</ul>
<h1 id="脚本编写"><a href="#脚本编写" class="headerlink" title="脚本编写"></a>脚本编写</h1><blockquote>
<p>详细可以看<a href="https://wyagd001.github.io/v2/docs/">脚本语言 | AutoHotkey v2</a>，这里只介绍基础编写</p>
</blockquote>
<h2 id="热键标记"><a href="#热键标记" class="headerlink" title="热键标记"></a>热键标记</h2><p>常用热键标记：</p>
<ul>
<li><code>#</code> ：win 键</li>
<li><code>!</code> ：alt</li>
<li><code>^</code> ：ctrl</li>
<li><code>+</code> ：shift</li>
<li><code>&amp;</code> ：用于连接两个按键(含鼠标按键) 合并成一个自定义热键</li>
</ul>
<blockquote>
<p><code>^q</code> 即代表ctrl + q</p>
</blockquote>
<p><code>::</code>连接符，当执行前面的后面的也会被执行</p>
<h2 id="打开程序-网页"><a href="#打开程序-网页" class="headerlink" title="打开程序 &amp; 网页"></a>打开程序 &amp; 网页</h2><p>可以使用<em><strong>Run</strong></em>函数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; 打开一个程序，为了不报错我建议大家用绝对路径:</span><br><span class="line">; 当然一些程序并不需要完整路径, 如 Windows 标准程序:</span><br><span class="line">Run &quot;notepad.exe&quot;</span><br><span class="line"></span><br><span class="line">; 使用内置变量来打开 &quot;我的文档&quot;:</span><br><span class="line">Run A_MyDocuments</span><br><span class="line"></span><br><span class="line">; 打开一个网址:</span><br><span class="line">Run &quot;https://www.autohotkey.com&quot;</span><br></pre></td></tr></table></figure>

<h2 id="关于开机自启"><a href="#关于开机自启" class="headerlink" title="关于开机自启"></a>关于开机自启</h2><p>把需要开机启动的脚本，放入 “启动” 文件夹即可。</p>
<p>目录：{C:\Users\username\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup}</p>
<h2 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h2><ul>
<li>一个脚本里可以有多个热键</li>
<li>支持函数&#x2F;变量…，大家可以自己探索QoQ</li>
</ul>
<hr>
<h1 id="一些案例分享"><a href="#一些案例分享" class="headerlink" title="一些案例分享"></a>一些案例分享</h1><h2 id="ctrl-空格-窗口置顶-取消置顶"><a href="#ctrl-空格-窗口置顶-取消置顶" class="headerlink" title="ctrl 空格 窗口置顶&#x2F;取消置顶"></a>ctrl 空格 窗口置顶&#x2F;取消置顶</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">^SPACE::  ; Ctrl + 空格 键切换置顶状态</span><br><span class="line">WinSet, AlwaysOnTop, Toggle, A</span><br><span class="line">return</span><br></pre></td></tr></table></figure>

<h2 id="文字替换-快捷输入"><a href="#文字替换-快捷输入" class="headerlink" title="文字替换&#x2F;快捷输入"></a>文字替换&#x2F;快捷输入</h2><p>ps：这里用了<a href="https://zhuanlan.zhihu.com/p/35379309">crystal</a>的例子</p>
<p>键盘输入 <code>/2</code>、<code>/h</code> + Tab、空格或回车，触发缩写功能，自动快速输入对应文本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; / + 缩写 触发，格式 “ ::/缩写::文本 ”</span><br><span class="line">::/qm::123456@qq.com</span><br><span class="line">::/zw::输入中文符号 、 也可触发</span><br><span class="line">::/2::您好，请问有什么可以帮助您的吗？</span><br><span class="line">::/h::哈哈哈哈</span><br><span class="line"></span><br><span class="line">; 结合快捷键命令，按 alt + 1 触发，</span><br><span class="line">; 以下是一条完整的命令，“!1” 为快捷键设置，Send 后跟文本</span><br><span class="line">!1::</span><br><span class="line">Send 快捷键触发输出</span><br><span class="line">return</span><br></pre></td></tr></table></figure>
<p><span class = "inline-note" align = "center">这个真的超级好用，主要是因为摸鱼的时候没法把看番的窗口置顶所以才有了这个OuO</span></p>
]]></content>
      <categories>
        <category>利器OuO</category>
      </categories>
      <tags>
        <tag>AutoHotkey</tag>
        <tag>软件</tag>
        <tag>脚本</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop搭建教程</title>
    <url>/LanBlog/hadoop2.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>
<p>在<a href="https://lanoao.github.io/LanBlog/hadoop1.html">Hadoop入门 </a>中，为大家简单介绍了 <a href="https://hadoop.apache.org/docs/">Hadoop</a> 。</p>
<p>在本文，我将为大家演示基于 linux 的 Hadoop 搭建。</p>
<span id="more"></span>

<blockquote>
<p><strong>本文所用软件版本:</strong></p>
<p>CentOS 7<br>Vmware 16<br>Xshell 7<br>Xftp 7</p>
</blockquote>
<div class="note primary"><p><strong>在开始之前你需要提前下载：</strong></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <a href="https://www.vmware.com/products/desktop-hypervisor/workstation-and-fusion">VMwareWworkstation Pro</a> 虚拟机管理软件</li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://mirrors.aliyun.com/centos/7/isos/x86_64/">CentOS 7 镜像</a>或者其他版本的镜像</li>
</ul>
<p>PS. 镜像下载时间超长</p>
<p><strong>你需要提前准备:</strong></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 一台配置好 <em><a href="#%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE">网络</a>&amp;主机名&amp;配置好xshell</em> 的虚拟机</li>
</ul>
</div>



<hr>
<p><span class = "inline-note" title ="小提示">本文将以初学者的视角进行详细讲解，左侧配有目录，大家按需选择阅读章节OuO。</p>
<p>全文中的重点内容都采用与本条相同的样式，鼠标悬停即可显示简要说明，方便快速理解。</p>
</span>

<h1 id="VMware-软件使用"><a href="#VMware-软件使用" class="headerlink" title="VMware 软件使用"></a>VMware 软件使用</h1><p>具体从软件配置到创建虚拟机这里不再赘述，大家可以自行搜索，这里只展示我觉得需要注意的点</p>
<h2 id="网络设置"><a href="#网络设置" class="headerlink" title="网络设置"></a>网络设置</h2><p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/image-20250814221946282.png"></p>
<div class="tabs" id="vmware"><ul class="nav-tabs"><li class="tab active"><a href="#vmware-1">桥接模式</a></li><li class="tab"><a href="#vmware-2">NAT模式</a></li><li class="tab"><a href="#vmware-3">仅主机模式</a></li></ul><div class="tab-content"><div class="tab-pane active" id="vmware-1"><p>桥接模式会直接把虚拟机连接到物理网络，就像一台真实电脑。<br><strong>虚拟机直接使用主机所在的局域网IP</strong></p></div><div class="tab-pane" id="vmware-2"><p>NAT模式会通过主机共享网络连接，虚拟机和外网通信时由主机做中转。<br><strong>虚拟机通过主机的网络访问外网</strong></p></div><div class="tab-pane" id="vmware-3"><p>仅主机模式下，虚拟机只能和主机互通，不能访问外网。<br><strong>适合内网测试或安全环境</strong></p></div></div></div>

<hr>
<h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemcttl stop firewalld    --关闭防火墙</span><br><span class="line">systemctl disable firewalld    --永久关闭防火墙</span><br></pre></td></tr></table></figure>

<h1 id="jdk配置"><a href="#jdk配置" class="headerlink" title="jdk配置"></a>jdk配置</h1><h2 id="1-使用Xftp传输压缩包并解压"><a href="#1-使用Xftp传输压缩包并解压" class="headerlink" title="1.使用Xftp传输压缩包并解压"></a>1.使用Xftp传输压缩包并解压</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@master opt]# pwd</span><br><span class="line">/opt</span><br><span class="line">[root@master opt]# mkdir module #解压后的位置</span><br><span class="line">[root@master opt]# mkdir software #压缩包</span><br><span class="line">[root@master opt]# cd software</span><br><span class="line">[root@master software]# ll</span><br><span class="line">total 1488592</span><br><span class="line">-rw-r--r--. 1 root root  87380462 Aug 27 10:59 apache-flume-1.11.0-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root  22347776 Aug 27 10:59 apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root  14853274 Aug 27 10:59 apache-zookeeper-3.8.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 730107476 Aug 27 10:59 hadoop-3.3.6.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 141600542 Aug 27 10:59 jdk-8u401-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 528015360 Aug 27 10:59 mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">[root@master software]# tar -zvxf jdk-8u401-linux-x64.tar.gz -C ../module #解压jdk压缩包</span><br><span class="line">[root@master software]# tar -zvxf hadoop-3.3.6.tar.gz -C ../module/ #解压hadoop压缩包</span><br><span class="line">[root@master software]# cd ../module/                              </span><br><span class="line">[root@master module]# ll</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 10 1000 1000 4096 Jun 18  2023 hadoop-3.3.6</span><br><span class="line">drwxr-x---.  8 root root 4096 Aug 27 11:02 jdk1.8.0_401</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-配置环境变量"><a href="#2-配置环境变量" class="headerlink" title="2.配置环境变量"></a>2.配置环境变量</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@master module]# cd jdk1.8.0_401/</span><br><span class="line">[root@master jdk1.8.0_401]# pwd</span><br><span class="line">/opt/module/jdk1.8.0_401</span><br><span class="line"></span><br><span class="line">[root@master module]# vi /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_401</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">[root@master module]# source /etc/profile #刷新环境变量</span><br><span class="line">[root@master ~]# jps</span><br><span class="line">508 Jps</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="克隆三台虚拟机"><a href="#克隆三台虚拟机" class="headerlink" title="克隆三台虚拟机"></a>克隆三台虚拟机</h1><p>在克隆之前建议配置好<a href="#1.%E6%9B%B4%E6%94%B9hosts">hosts文件</a>为下一步做准备</p>
<p>配置好后依次更改主机名</p>
<p>这里不过多赘述</p>
<h1 id="配置免密—SSH"><a href="#配置免密—SSH" class="headerlink" title="配置免密—SSH"></a>配置免密—SSH</h1><h2 id="1-更改hosts"><a href="#1-更改hosts" class="headerlink" title="1.更改hosts"></a>1.更改hosts</h2><p>三台虚拟机都更改</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vi /etc/hosts</span><br><span class="line">[ip-1] [hostname-1]</span><br><span class="line">[ip-1] [hostname-2]</span><br><span class="line">[ip-1] [hostname-3]</span><br></pre></td></tr></table></figure>

<h2 id="2-生成并传输密钥"><a href="#2-生成并传输密钥" class="headerlink" title="2.生成并传输密钥"></a>2.生成并传输密钥</h2><p>在<span class = "inline-note " title = "一定要更改好hosts后再生成">主节点生成密钥</span></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa #生成密钥</span><br><span class="line">ssh-copy-id [hostname-1&amp;2&amp;3] #传输密钥</span><br></pre></td></tr></table></figure>

<p>输入 yes+对应主机的密码</p>
<p>成功后可以使用 <code>ssh + [hostname-1&amp;2&amp;3]</code>进行测试</p>
<p><code>exit</code>命令即可退出</p>
<h1 id="配置Hadoop配置文件"><a href="#配置Hadoop配置文件" class="headerlink" title="配置Hadoop配置文件"></a>配置Hadoop配置文件</h1><p>以下配置文件的路径为<code>$hadoop_home/etc/hadoop/</code></p>
<h2 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/software/hadoop-3.3.4/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    --hadoop路径</span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/root/software/hadoop-3.3.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/root/software/hadoop-3.3.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/root/software/hadoop-3.3.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,</span><br><span class="line">HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,</span><br><span class="line">HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=$JAVA_HOME</span><br></pre></td></tr></table></figure>

<h2 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">三台机器的名字</span><br></pre></td></tr></table></figure>
<h1 id="配置并刷新环境变量"><a href="#配置并刷新环境变量" class="headerlink" title="配置并刷新环境变量"></a>配置并刷新环境变量</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#hadoop</span><br><span class="line">export HADOOP_HOME=/root/software/hadoop-3.3.4</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>
<p>刷新环境变量   <code>source /etc/profile</code></p>
<h1 id="SSH-传输"><a href="#SSH-传输" class="headerlink" title="SSH 传输"></a>SSH 传输</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp [-1246BCpqrv]  [-c cipher]  [-F ssh_config]  [-i identity_file]  [-l limit]  [-o ssh_option]  [-P port]  [-S program]  [[user@]host1:]file1 [...]  [[user@]host2:]file2</span><br></pre></td></tr></table></figure>
<p>依次传输Hadoop、环境变量到其他虚拟机</p>
<h1 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h1><p><span class = "inline-note" title ="注意都在主节点运行"><strong>Hadoop 启动与停止命令一览</strong></span></p>
<h2 id="1-启动-停止所有守护进程"><a href="#1-启动-停止所有守护进程" class="headerlink" title="1. 启动&#x2F;停止所有守护进程"></a>1. 启动&#x2F;停止所有守护进程</h2><ul>
<li><p><strong>启动所有守护进程</strong></p>
<p><code>sbin/start-all.sh</code></p>
</li>
</ul>
<p>启动内容包括：NameNode、Secondary NameNode、DataNode、ResourceManager、NodeManager</p>
<ul>
<li><p><strong>停止所有守护进程</strong></p>
<p><code>sbin/stop-all.sh</code></p>
</li>
</ul>
<p>停止内容包括：NameNode、Secondary NameNode、DataNode、ResourceManager、NodeManager</p>
<hr>
<h2 id="2-HDFS-守护进程"><a href="#2-HDFS-守护进程" class="headerlink" title="2. HDFS 守护进程"></a>2. HDFS 守护进程</h2><ul>
<li><p><strong>启动 HDFS 守护进程</strong></p>
<p><code>sbin/start-dfs.sh</code></p>
</li>
</ul>
<p>启动内容：NameNode、Secondary NameNode、DataNode</p>
<ul>
<li><p><strong>停止 HDFS 守护进程</strong></p>
<p><code>sbin/stop-dfs.sh</code></p>
</li>
</ul>
<p>停止内容：NameNode、Secondary NameNode、DataNode</p>
<h3 id="单独启动-停止-HDFS-守护进程"><a href="#单独启动-停止-HDFS-守护进程" class="headerlink" title="单独启动&#x2F;停止 HDFS 守护进程"></a>单独启动&#x2F;停止 HDFS 守护进程</h3><ul>
<li><p><strong>NameNode</strong></p>
<p><code>sbin/hadoop-daemons.sh start namenode</code></p>
<p><code>sbin/hadoop-daemons.sh stop namenode</code></p>
</li>
<li><p><strong>DataNode</strong></p>
<p><code>sbin/hadoop-daemons.sh start datanode</code></p>
<p><code>sbin/hadoop-daemons.sh stop datanode</code></p>
</li>
<li><p><strong>Secondary NameNode</strong></p>
<p><code>sbin/hadoop-daemons.sh start secondarynamenode</code></p>
<p><code>sbin/hadoop-daemons.sh stop secondarynamenode</code></p>
</li>
</ul>
<hr>
<h2 id="3-YARN-守护进程"><a href="#3-YARN-守护进程" class="headerlink" title="3. YARN 守护进程"></a>3. YARN 守护进程</h2><ul>
<li><p><strong>启动 YARN 守护进程</strong></p>
<p><code>sbin/start-yarn.sh</code></p>
</li>
</ul>
<p>启动内容：ResourceManager、NodeManager</p>
<ul>
<li><p><strong>停止 YARN 守护进程</strong></p>
<p><code>sbin/stop-yarn.sh</code></p>
</li>
</ul>
<p>停止内容：ResourceManager、NodeManager</p>
<h3 id="单独启动-停止-YARN-守护进程"><a href="#单独启动-停止-YARN-守护进程" class="headerlink" title="单独启动&#x2F;停止 YARN 守护进程"></a>单独启动&#x2F;停止 YARN 守护进程</h3><ul>
<li><p><strong>ResourceManager</strong></p>
<p><code>sbin/yarn-daemon.sh start resourcemanager</code></p>
<p>&#96;&#96;sbin&#x2F;yarn-daemon.sh stop resourcemanager&#96;</p>
</li>
<li><p><strong>NodeManager</strong></p>
<p><code>sbin/yarn-daemons.sh start nodemanager</code></p>
<p>&#96;&#96;sbin&#x2F;yarn-daemons.sh stop nodemanager&#96;</p>
</li>
</ul>
<hr>
<h2 id="4-MapReduce-JobHistory-服务"><a href="#4-MapReduce-JobHistory-服务" class="headerlink" title="4. MapReduce JobHistory 服务"></a>4. MapReduce JobHistory 服务</h2><ul>
<li><p><strong>启动 JobHistory</strong></p>
<p><code>sbin/mr-jobhistory-daemon.sh start historyserver</code></p>
</li>
<li><p><strong>停止 JobHistory</strong></p>
<p><code>sbin/mr-jobhistory-daemon.sh stop historyserver</code></p>
</li>
</ul>
<h1 id="测试是否成功"><a href="#测试是否成功" class="headerlink" title="测试是否成功"></a>测试是否成功</h1><ul>
<li><p>先使用jps查看进程，查看是否成功启动所有进程</p>
</li>
<li><p>打开网页 主节点的ip地址:9870<br>查看是否有web ui,在这里你能看到你所搭建的集群的基本信息</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>搭建</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop入门</title>
    <url>/LanBlog/hadoop1.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>
<p> 一些关于Hadoop的理论知识</p>
<span id="more"></span>
<blockquote>
<p>本篇文章将全篇以 Hadoop 2.x 为基础为大家介绍 Hadoop</p>
<blockquote>
<p>Hadoop 2.x 起，YARN 替代了原本的 JobTracker&#x2F;TaskTracker 模式，引入 ResourceManager 与 ApplicationMaster，将资源管理与作业调度解耦。</p>
</blockquote>
</blockquote>
<hr>
<h1 id="Hadoop-是什么？"><a href="#Hadoop-是什么？" class="headerlink" title="Hadoop 是什么？"></a>Hadoop 是什么？</h1><p><a class="inline-note" title="由 Apache 基金会开发，使用 Java 编写" href="https://hadoop.apache.org/">Hadoop</a> 是一个开源的、可扩展的、分布式的大数据处理框架。</p>
<p>它的设计理念是：<strong>将数据分布到多台普通机器上，并让程序靠近数据运行（移动‘计算’，而不是移动‘数据’）</strong>。</p>
<h2 id="优势与缺点"><a href="#优势与缺点" class="headerlink" title="优势与缺点"></a>优势与缺点</h2><p>✅ <strong>优势</strong></p>
<ul>
<li><strong>高可靠性</strong>：Hadoop 通过数据<code>多副本机制</code>，确保即使部分节点发生故障，数据依然不会丢失。</li>
<li><strong>高扩展性</strong>：可<code>横向扩展</code>到成百上千台普通服务器，支持大规模数据处理。</li>
<li><strong>高效性</strong>：基于 MapReduce <code>并行处理</code>模型，能够显著加快数据处理速度。</li>
<li><strong>高容错性</strong>：节点或任务失败时，系统能<code>自动检测并重新调度任务</code>，保障任务完成。</li>
</ul>
<p>❎ <strong>缺点</strong></p>
<ul>
<li>MapReduce 编程模型对<strong>实时性不友好</strong>（批处理，延迟高）；</li>
<li>编程门槛相对较高；</li>
<li>数据随机访问性能差；</li>
<li>运维成本大，对硬件和配置依赖强。</li>
</ul>
<h1 id="Hadoop-生态系统"><a href="#Hadoop-生态系统" class="headerlink" title="Hadoop 生态系统"></a>Hadoop 生态系统</h1><table>
<thead>
<tr>
<th>组件</th>
<th>功能描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Hadoop HDFS</strong></td>
<td>Hadoop 分布式存储系统</td>
</tr>
<tr>
<td><strong>MapReduce</strong></td>
<td>并行处理框架</td>
</tr>
<tr>
<td><strong>YARN</strong></td>
<td>资源管理与调度</td>
</tr>
<tr>
<td><strong>Hive</strong></td>
<td>基于 SQL 的数据仓库工具</td>
</tr>
<tr>
<td><strong>Pig</strong></td>
<td>数据流脚本语言</td>
</tr>
<tr>
<td><strong>HBase</strong></td>
<td>分布式列式数据库</td>
</tr>
<tr>
<td><strong>Sqoop</strong></td>
<td>与关系型数据库之间导入导出</td>
</tr>
<tr>
<td><strong>Flume</strong></td>
<td>收集日志数据流入 Hadoop</td>
</tr>
<tr>
<td><strong>Zookeeper</strong></td>
<td>分布式协调服务，提供统一的注册、选举和配置服务（常用于 HBase）</td>
</tr>
<tr>
<td><strong>Oozie</strong></td>
<td>工作流调度工具</td>
</tr>
<tr>
<td><strong>Spark</strong></td>
<td>基于内存的快速大数据计算框架</td>
</tr>
</tbody></table>
<p>接下来为大家介绍三个核心组件（HDFS、MapReduce、YARN）^^</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>分布式文件系统，负责<strong>存储数据</strong>。</p>
<ul>
<li><p>类似于普通文件系统，但它将文件切分成多个块，分散存储在集群中的多台机器上。</p>
</li>
<li><p>每个数据块默认会备份三份，保证<strong>容错性和高可用性</strong>。</p>
</li>
<li><p>主节点：<code>NameNode</code>，存储元数据（文件名、位置等）；</p>
</li>
<li><p>从节点：<code>DataNode</code>，存储真实数据块。</p>
</li>
</ul>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>分布式计算框架，负责<strong>计算数据</strong>。</p>
<ul>
<li><p>编程模型包含两个阶段：Map（映射） 和 Reduce（归约）；</p>
</li>
<li><p>用户编写 Map 和 Reduce 函数，框架负责将任务分发到多台机器上执行；</p>
</li>
<li><p>特点是<strong>高度容错</strong>，适合批处理。</p>
</li>
</ul>
<blockquote>
<p>它会把计算任务移动到离数据最近的地方进行执行，因为移动大量数据是非常耗费资源的。</p>
</blockquote>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p>资源管理系统，负责<strong>资源调度</strong>。</p>
<ul>
<li><p>资源管理和任务调度&#x2F;监控功分割成不同的进程</p>
</li>
<li><p>主节点：<code>ResourceManager</code>，负责给 application 分配资源</p>
</li>
<li><p>从节点：<code>NodeManager</code> ，负责监控容器使用资源情况，并把资源使用情况报告 ResourceManager。这里所说的资源一般是指CPU、内存、磁盘、网络等。</p>
</li>
</ul>
<h1 id="Hadoop工作方式"><a href="#Hadoop工作方式" class="headerlink" title="Hadoop工作方式"></a>Hadoop工作方式</h1><h2 id="主从工作方式"><a href="#主从工作方式" class="headerlink" title="主从工作方式"></a>主从工作方式</h2><p>一个 Master 和多个 Slave 节点，Slave 节点可以扩招到1000个</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>主节点（Master）</th>
<th>从节点（Slave）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>主要职责</strong></td>
<td>负责元数据管理、任务调度、资源分配等控制类工作</td>
<td>执行实际的存储或计算任务，如保存数据块、运行 MapReduce 任务等</td>
</tr>
<tr>
<td><strong>HDFS 中角色</strong></td>
<td><code>NameNode</code>（存储文件系统的目录结构、数据块位置等元数据）</td>
<td><code>DataNode</code>（存储实际的数据块）</td>
</tr>
<tr>
<td><strong>YARN 中角色</strong></td>
<td><code>ResourceManager</code>（管理集群资源）<br><code>ApplicationMaster</code>（调度某个应用的任务）</td>
<td><code>NodeManager</code>（管理本节点资源并报告给 ResourceManager）<br><code>Container</code>（执行任务）</td>
</tr>
<tr>
<td><strong>容错机制</strong></td>
<td>通常单点故障（如 <code>NameNode</code>）需配置**高可用模式（HA）**来避免整个集群瘫痪</td>
<td>任意从节点故障，系统可自动将任务&#x2F;副本转移到其他节点，影响较小</td>
</tr>
<tr>
<td><strong>故障影响</strong></td>
<td>故障可能导致整个系统不可用或任务调度失败</td>
<td>局部计算或存储失败，影响有限，系统具备自动容错能力</td>
</tr>
<tr>
<td><strong>硬件要求</strong></td>
<td>对稳定性、内存、网络、磁盘性能要求较高</td>
<td>可使用普通服务器，但需数量足够以提供分布式计算&#x2F;存储能力</td>
</tr>
<tr>
<td><strong>部署建议</strong></td>
<td>建议部署在可靠性高、性能优的节点上，并开启冗余&#x2F;主备机制</td>
<td>可大规模横向扩展，支持动态加入或移除</td>
</tr>
</tbody></table>
<h2 id="守护进程"><a href="#守护进程" class="headerlink" title="守护进程"></a>守护进程</h2><p>Hadoop 主要有4个守护进程:</p>
<ul>
<li>NameNode ：它是HDFS运行在Master节点守护进程。</li>
<li>DataNode：它是 HDFS 运行在Slave节点守护进程。</li>
<li>ResourceManager：它是 Yarn 运行在 Master 节点守护进程。</li>
<li>NodeManager：它是 Yarn 运行在 Slave 节点的守护进程。</li>
</ul>
<p>除了这些，可能还会有 secondary NameNode，standby NameNode，Job HistoryServer 等进程。</p>
<h1 id="Hadoop-常用命令"><a href="#Hadoop-常用命令" class="headerlink" title="Hadoop 常用命令"></a>Hadoop 常用命令</h1><p><a href="https://hadoop.apache.ac.cn/docs/stable/hadoop-project-dist/hadoop-common/CommandsManual.html">Apache Hadoop 3.3.6 – Hadoop 命令指南 - Hadoop 框架</a></p>
<h2 id="📁-HDFS-文件系统命令"><a href="#📁-HDFS-文件系统命令" class="headerlink" title="📁 HDFS 文件系统命令"></a>📁 HDFS 文件系统命令</h2><table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>hadoop fs -ls /</code></td>
<td>查看根目录下的文件和目录</td>
</tr>
<tr>
<td><code>hadoop fs -mkdir /data</code></td>
<td>创建新目录 <code>/data</code></td>
</tr>
<tr>
<td><code>hadoop fs -put localfile.txt /data/</code></td>
<td>上传本地文件到 HDFS</td>
</tr>
<tr>
<td><code>hadoop fs -get /data/file.txt ./</code></td>
<td>下载 HDFS 文件到本地</td>
</tr>
<tr>
<td><code>hadoop fs -cat /data/file.txt</code></td>
<td>查看 HDFS 中的文件内容</td>
</tr>
<tr>
<td><code>hadoop fs -rm /data/file.txt</code></td>
<td>删除 HDFS 中的文件</td>
</tr>
<tr>
<td><code>hadoop fs -rm -r /data/</code></td>
<td>递归删除目录及其内容</td>
</tr>
<tr>
<td><code>hadoop fs -du -h /data</code></td>
<td>查看目录或文件占用空间</td>
</tr>
<tr>
<td><code>hadoop fs -chmod 755 /data</code></td>
<td>修改 HDFS 中文件权限</td>
</tr>
</tbody></table>
<hr>
<h2 id="🚀-启动-关闭-Hadoop-集群"><a href="#🚀-启动-关闭-Hadoop-集群" class="headerlink" title="🚀 启动&#x2F;关闭 Hadoop 集群"></a>🚀 启动&#x2F;关闭 Hadoop 集群</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>start-dfs.sh</code></td>
<td>启动 HDFS（NameNode 和 DataNode）</td>
</tr>
<tr>
<td><code>stop-dfs.sh</code></td>
<td>关闭 HDFS</td>
</tr>
<tr>
<td><code>start-yarn.sh</code></td>
<td>启动 YARN（ResourceManager 和 NodeManager）</td>
</tr>
<tr>
<td><code>stop-yarn.sh</code></td>
<td>关闭 YARN</td>
</tr>
<tr>
<td><code>mr-jobhistory-daemon.sh start historyserver</code></td>
<td>启动 MapReduce JobHistory 服务（可选）</td>
</tr>
<tr>
<td><code>mr-jobhistory-daemon.sh stop historyserver</code></td>
<td>停止 JobHistory 服务</td>
</tr>
</tbody></table>
<hr>
<h2 id="🧰-MapReduce-作业相关命令"><a href="#🧰-MapReduce-作业相关命令" class="headerlink" title="🧰 MapReduce 作业相关命令"></a>🧰 MapReduce 作业相关命令</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>hadoop jar yourjob.jar MainClass /input /output</code></td>
<td>提交 MapReduce 作业</td>
</tr>
<tr>
<td><code>yarn application -list</code></td>
<td>查看正在运行的应用</td>
</tr>
<tr>
<td><code>yarn application -status </code></td>
<td>查看某个应用的状态</td>
</tr>
<tr>
<td><code>yarn application -kill </code></td>
<td>杀掉某个应用</td>
</tr>
</tbody></table>
<hr>
<h2 id="📄-日志查看命令"><a href="#📄-日志查看命令" class="headerlink" title="📄 日志查看命令"></a>📄 日志查看命令</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>jps</code></td>
<td>查看 Hadoop 组件进程（需安装 JDK）</td>
</tr>
<tr>
<td><code>tail -f $HADOOP_HOME/logs/*.log</code></td>
<td>实时查看日志输出</td>
</tr>
<tr>
<td><code>less $HADOOP_HOME/logs/hadoop-*.log</code></td>
<td>分页查看日志</td>
</tr>
</tbody></table>
<hr>
<h2 id="🧪-其他实用命令"><a href="#🧪-其他实用命令" class="headerlink" title="🧪 其他实用命令"></a>🧪 其他实用命令</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>hdfs dfsadmin -report</code></td>
<td>查看集群节点、容量、使用情况等摘要</td>
</tr>
<tr>
<td><code>hdfs dfsadmin -safemode get</code></td>
<td>查看当前是否处于安全模式</td>
</tr>
<tr>
<td><code>hdfs dfsadmin -safemode leave</code></td>
<td>退出安全模式</td>
</tr>
<tr>
<td><code>hdfs dfs -test -e /path</code></td>
<td>判断某路径是否存在（返回码为 0 表示存在）</td>
</tr>
<tr>
<td><code>hdfs namenode -format</code></td>
<td>格式化 HDFS（⚠️仅首次初始化）</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>centos更换yum源</title>
    <url>/LanBlog/centos_yum.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>
<p>centos7更换为国内yum源</p>
<span id="more"></span>
<h1 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h1><p>mv &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.bak</p>
<h1 id="更新yum源"><a href="#更新yum源" class="headerlink" title="更新yum源"></a>更新yum源</h1><p><span class=“inline-note” title="看什么看，没有注释EmE">这里的命令是centos7的更新命令，可以根据自己的的版本替换一下</span><br>wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo <a href="http://mirrors.aliyun.com/repo/Centos-7.repo">http://mirrors.aliyun.com/repo/Centos-7.repo</a></p>
<h1 id="更新缓存"><a href="#更新缓存" class="headerlink" title="更新缓存"></a>更新缓存</h1><p>yum makecache</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博文编写</title>
    <url>/LanBlog/hexo-optimize.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>编写博文的笔记</p>
<span id="more"></span>
<h1 id="网页内容"><a href="#网页内容" class="headerlink" title="网页内容"></a>网页内容</h1><h2 id="侧栏"><a href="#侧栏" class="headerlink" title="侧栏"></a>侧栏</h2><p>名字: 链接 || 图标名<br>social:<br>图标名必须在<a href="http://fontawesome.dashgame.com/" title="external" target="">Fontawesome</a>里有</p>
<h1 id="文章选项"><a href="#文章选项" class="headerlink" title="文章选项"></a>文章选项</h1><p>这里是文章的选项👀</p>
<h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><p>在Font-matter加：</p>
<figure class="highlight plaintext"><figcaption><span>tag-e.g.</span></figcaption><table><tr><td class="code"><pre><span class="line">tags:</span><br><span class="line">    - 笔记</span><br><span class="line">    - 博客</span><br></pre></td></tr></table></figure>

<h1 id="文本内容"><a href="#文本内容" class="headerlink" title="文本内容"></a>文本内容</h1><p>这里是文章内容编写相关👀</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% link text url [external] [title] %&#125;</span><br></pre></td></tr></table></figure>
<p>text：链接显示的文字<br>url：链接的地址<br>[external]：可选，如果加上 external，链接会在新标签页打开（即添加 target&#x3D;”_blank”）<br>[title]：可选，设置 title 属性（鼠标悬停时显示的文字）</p>
<h2 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h2><p>有两种写法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% codeblock [title] %&#125;</span><br><span class="line">&#123;% endcodeblock %&#125;</span><br></pre></td></tr></table></figure>
<p>或者三个“&#96;”</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% blockquote [作者[, 来源]] [链接地址] [链接标题] %&#125;</span><br><span class="line">内容</span><br><span class="line">&#123;% endblockquote %&#125;</span><br></pre></td></tr></table></figure>

<blockquote><p>内容</p>
<footer><strong>[作者[</strong><cite>来源]] [链接地址] [链接标题]</cite></footer></blockquote>

<h2 id="标签插件"><a href="#标签插件" class="headerlink" title="标签插件"></a>标签插件</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% note warning %&#125;</span><br><span class="line">🤔 **随手记：** 这个 API 文档写得跟谜语一样，看三遍才明白……</span><br><span class="line">&#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>
<div class="note warning"><p>🤔 <strong>随手记：</strong> 这个 API 文档写得跟谜语一样，看三遍才明白……</p>
</div>
<table>
<thead>
<tr>
<th>语法</th>
<th>效果说明</th>
<th>常见用途</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 学习笔记</title>
    <url>/LanBlog/docker_note1.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>
<p>初学者的docker入门笔记</p>
<span id="more"></span>
<p><a href="https://docs.docker.com/">Docker文档</a></p>
<h1 id="Docker概述"><a href="#Docker概述" class="headerlink" title="Docker概述"></a>Docker概述</h1><h2 id="Docker-出现的原因"><a href="#Docker-出现的原因" class="headerlink" title="Docker 出现的原因"></a>Docker 出现的原因</h2><p><u>解决环境一致性问题</u><br>当我们开发一个项目时，通常需要依赖大量的框架、库、插件、环境变量等。例如，某个项目可能依赖：</p>
<ul>
<li>Node.js 特定版本</li>
<li>MySQL 数据库</li>
<li>Redis 缓存</li>
<li>某些 C++ 编译器或 Python 包</li>
</ul>
<p>这些依赖项在我们本地电脑上能正常运行，并不意味着在他人的电脑或线上服务器上也能顺利部署。<strong>不同系统、不同版本、配置差异</strong>都会带来兼容性问题，这就是我们常说的 <strong>“环境不一致”</strong> 问题。</p>
<p>在docker之前，大家使用虚拟机技术解决这个问题<br> ——但是它的本质是运用<strong>使用软件模拟一整套硬件系统</strong>，体积大、速度慢、资源消耗高<br> 而 Docker 是通过 <strong>操作系统级虚拟化</strong>，模拟出 轻量 隔离 的运行环境。</p>
<h2 id="Docker-基本结构"><a href="#Docker-基本结构" class="headerlink" title="Docker 基本结构"></a>Docker 基本结构</h2><p><img data-src="https://docs.docker.com/get-started/images/docker-architecture.webp"></p>
<div class="tabs" id="docker-基础概念"><ul class="nav-tabs"><li class="tab active"><a href="#docker-基础概念-1">镜像（Image）</a></li><li class="tab"><a href="#docker-基础概念-2">容器（Container）</a></li><li class="tab"><a href="#docker-基础概念-3">仓库（Repository）</a></li></ul><div class="tab-content"><div class="tab-pane active" id="docker-基础概念-1"><p>类似于虚拟机中的镜像，是一个包含有文件系统的面向Docker引擎的只读模板。<br>任何应用程序运行都需要环境，而镜像就是用来提供这种运行环境的。例如一个Ubuntu镜像就是一个包含Ubuntu操作系统环境的模板，同理在该镜像上装上Apache软件，就可以称为Apache镜像。</p></div><div class="tab-pane" id="docker-基础概念-2"><p>Docker 容器就像一台台运行的虚拟机，<br>里面运行你的应用程序。<br>它们是相互隔离的，互不影响。</p></div><div class="tab-pane" id="docker-基础概念-3"><p>类似于代码仓库，这里是镜像仓库，是Docker用来集中存放镜像文件的地方。<br>注意与注册服务器（Registry）的区别：注册服务器是存放仓库的地方，一般会有多个仓库；而仓库是存放镜像的地方，一般每个仓库存放一类镜像，每个镜像利用tag进行区分，比如Ubuntu仓库存放有多个版本（12.04、14.04等）的Ubuntu镜像。</p></div></div></div>


<p>除了以上几个结构组成中重要的概念外，还有另一个重要的概念<br><strong>Dockerfile</strong>：<br>它像一个自动化的脚本，它主要用来创建我们之前讲到的镜像。</p>
<blockquote>
<p>他就好比把虚拟机中创建虚拟机并安装软件的过程压缩为一个脚本。</p>
</blockquote>
<h1 id="Docker-安装"><a href="#Docker-安装" class="headerlink" title="Docker 安装"></a>Docker 安装</h1><div class="note info"><p><a href="https://docs.docker.com/get-started/get-docker/">Docker Desktop 安装文档</a><br><a href="https://docs.docker.com/engine/install/">Docker Engine 安装文档</a></p>
</div>
<p>安装完成后可以使用<code>docker version</code>查看Docker的版本信息<br>查看Docker的帮助信息：<code>docker --help</code></p>
<h1 id="Docker-常用命令"><a href="#Docker-常用命令" class="headerlink" title="Docker 常用命令"></a>Docker 常用命令</h1><div class="note warning"><p><strong>列举所有的容器:</strong> <code>docker ps</code><br><strong>停止容器:</strong> <code>docker stop &lt;容器 ID&gt;</code><br><strong>重启容器:</strong> <code>docker restart &lt;容器 ID&gt;</code><br><strong>删除容器:</strong> <code>docker rm &lt;容器 ID&gt;</code><br><strong>启动一个远程 Shell:</strong> <code>docker exec -it&lt;容器 ID&gt; /bin/bash</code><br>只用 <code>-i</code> 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。</p>
<p>当 <code>-i</code> <code>-t</code> 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。</p>
</div>


<ol>
<li><p><code>docker run</code>: 运行一个容器。<br>示例：<code>docker run </code></p>
</li>
<li><p><code>docker ps</code>: 列出正在运行的容器。<br>示例：<code>docker ps</code></p>
</li>
<li><p><code>docker images</code>: 列出本地已有的镜像。<br>示例：<code>docker images</code></p>
</li>
<li><p><code>docker pull</code>: 从远程仓库下载镜像。<br>示例：<code>docker pull </code></p>
</li>
<li><p><code>docker stop</code>: 停止一个运行中的容器。<br>示例：<code>docker stop </code></p>
</li>
<li><p><code>docker rm</code>: 删除一个容器。<br>示例：<code>docker rm </code></p>
</li>
<li><p><code>docker rmi</code>: 删除一个镜像。<br>示例：<code>docker rmi </code></p>
</li>
<li><p><code>docker build</code>: 构建一个镜像。<br>示例：<code>docker build -t  </code></p>
</li>
<li><p><code>docker exec</code>: 在运行中的容器中执行命令。<br>示例：<code>docker exec  </code></p>
</li>
<li><p><code>docker logs</code>: 查看容器的日志。<br>示例：<code>docker logs </code></p>
</li>
<li><p><code>docker-compose up</code>: 使用Docker Compose启动容器。<br>示例：<code>docker-compose up</code></p>
</li>
<li><p><code>docker-compose down</code>: 停止并移除使用Docker Compose启动的容器。<br>示例：<code>docker-compose down</code></p>
</li>
<li><p><code>docker network ls</code>: 列出Docker网络。<br>示例：<code>docker network ls</code></p>
</li>
<li><p><code>docker network create</code>: 创建一个Docker网络。<br>示例：<code>docker network create </code></p>
</li>
<li><p><code>docker network connect</code>: 将容器连接到一个Docker网络。<br>示例：<code>docker network connect  </code></p>
</li>
<li><p><code>docker volume ls</code>: 列出Docker卷。<br>示例：<code>docker volume ls</code></p>
</li>
<li><p><code>docker volume create</code>: 创建一个Docker卷。<br>示例：<code>docker volume create </code></p>
</li>
<li><p><code>docker volume rm</code>: 删除一个Docker卷。<br>示例：<code>docker volume rm </code></p>
</li>
<li><p><code>docker inspect</code>: 检查容器、镜像、网络等的详细信息。<br>示例：<code>docker inspect </code></p>
</li>
<li><p><code>docker tag</code>: 创建一个标签来标识镜像。<br>示例：<code>docker tag  </code></p>
</li>
<li><p><code>docker push</code>: 将镜像推送到远程仓库。<br>示例：<code>docker push </code></p>
</li>
<li><p><code>docker login</code>: 登录到远程Docker仓库。<br>示例：<code>docker login</code></p>
</li>
<li><p><code>docker logout</code>: 从远程Docker仓库注销。<br>示例：<code>docker logout</code></p>
</li>
<li><p><code>docker restart</code>: 重启一个容器。<br>示例：<code>docker restart </code></p>
</li>
<li><p><code>docker pause</code>: 暂停一个容器的所有进程。<br>示例：<code>docker pause </code></p>
</li>
<li><p><code>docker unpause</code>: 恢复一个暂停的容器。<br>示例：<code>docker unpause </code></p>
</li>
<li><p><code>docker kill</code>: 强制停止一个容器。<br>示例：<code>docker kill </code></p>
</li>
<li><p><code>docker inspect</code>: 检查容器、镜像、网络等的详细信息。<br>示例：<code>docker inspect </code></p>
</li>
<li><p><code>docker cp</code>: 在容器和主机之间复制文件或目录。<br>示例：<code>docker cp : </code></p>
</li>
<li><p><code>docker stats</code>: 实时显示容器的资源使用情况。<br>示例：<code>docker stats </code></p>
</li>
<li><p><code>docker attach</code>: 连接到正在运行的容器的标准输入、输出和错误流。<br>示例：<code>docker attach </code></p>
</li>
<li><p><code>docker top</code>: 显示容器中运行的进程列表。<br>示例：<code>docker top </code></p>
</li>
<li><p><code>docker commit</code>: 创建一个新的镜像，基于正在运行的容器。<br>示例：<code>docker commit  </code></p>
</li>
<li><p><code>docker system prune</code>: 清理无用的镜像、容器和卷。<br>示例：<code>docker system prune</code></p>
</li>
<li><p><code>docker version</code>: 显示Docker客户端和服务器的版本信息。<br>示例：<code>docker version</code></p>
</li>
</ol>
<hr>
<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/23599229">只要一小时，零基础入门Docker - 知乎</a><br><a href="https://blog.csdn.net/leah126/article/details/131871717">Docker入门教程（非常详细）从零基础入门到精通，看完这一篇就够了_docker教程-CSDN博客</a><br><a href="https://github.com/feixuek/docker?tab=readme-ov-file">Github-Docker中文</a></p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>明日清单</title>
    <url>/LanBlog/todo_list.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="a593c0d2adaf6101f24e68d7235ac11aa7427d581276459d8806349b9a5b70f3">4139d70b29d5f8e74d5ab0d506a8a2d1c5ffdbef7010aa0eff7d387d74697f4aa20462941bd05263601c92a91fe171d1953b25d9a625c4acd2cc3deb83b3fe8a099c2c3cc4b9c445dbf8965b9533cfc826c7e080ce0becf6e7aec7bacfefb72c1f108aead79566f3d8aaf496d6f8a33aa944f617104e2e0fea7b003fd004899b4ee3d31c908353086549b6852326c291f9f23883465100a7039e697d78c79ebb83a968fe3b06fb5db3698e282dc1f0160a5bea1ed387dac6f62dafc99c0a4ad07bea820a7bc0e84fbc711aed199cae82eb72162acfabab8e7bb3a694c7942e813ee9e408eec6af88a33caaa55dc0d0de8f8bb63048dff2ded7dc6d14c7c3b4cbe71b91e138facdfc01ca4adc58e3561627251fcb94a1d6eed370c3ac8f6c2a33a4aead0ddb35d55d6e1c1fb5dba0ee3ea82dd84f72fe5c5dd394a23195581a4ad04e4b2c7d1d305f2d6885b8e8338001977fb87679eb2b81cece9daa9846c81726f1b7a9195bfe05f6013871b17e9017d3b2f071414047f55508cc4440a09348dd21f36242d80076340ed94977a3616b8558d678a0225f151014ec507aef78f40d352fd8938df237f50ec3f64d4e1ed0cd4523f3e38631ba3980feda2663dde3edb64952b21da904d27d7501d9e7ac414ef8e93461cbd9c000cd42e6be8b33544c2061564ee5f2cada01622b751e952b96100a4c6886414372d19969cb57851a873f8cff5f140942f48a3b7aea3c52938f1a4126fb151acdf502deddec6d8448d8e7826ea53343c1d5704636c47c684f8c12592586e5983e204f94a3f1e5c2f9489e09fcb2f2f35602245964a502831300030fe548baacebdae63560e7ee2be7d76f6682116852c01035ae3869bb44f155794fbd32df3158bc9b5d077b92d6a20676c496d94f9b9af4a6b954fb9ea633a293ab9e33823a4bdc7a48bbe31d0193d0d1c439982e003afc1aceecc4f0a44f3a0636c2f706042f7d20761b2712310546fadfd2db54ea72581882abd3daefea06e30bdf48b1afa188b24297982575a47f1d6e685367cb92b2955b29b6481e693e3cfac5e09bb6eb91f031aa33967ac9a4e70baa907086ea74853efc3067be5cebc4e0190a2c61e4738c88a4706ae45662c42bf98faf15e4189f9b1a3c3723048e83eab23fb24261331a3350147238d9c2f19e366d73c7633a5b85c37d08509b8c4e918f508fa61e7691ce1442b66165c5b80ceff9aef1f0ff7696aa11943e451db3d7600f4674685eecc112b643ef205ae3d33f7f465f6cf11a8d782b748221e0bc41b0a46be8ef5fca5c0103867a4f</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-xray">
      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">您好, 这里需要密码.</span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/LanBlog/lib/hbe.js"></script><link href="/LanBlog/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>清单</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生实践：智能计算平台构建与研发</title>
    <url>/LanBlog/ccf_1.html</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><style>
    .inline-note {
      display: inline-block;
      background-color: #fffbe6;
      color: #333;
      border-left: 4px solid #f7c948;
      padding: 0.2em 0.6em;
      margin: 0 0.2em;
      font-size: 0.95em;
      border-radius: 3px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      font-style: italic;
      cursor: help;
      transition: all 0.2s ease;
    }

    .inline-note:hover {
      background-color: #fff3bf;
      box-shadow: 0 0 5px rgba(247, 201, 72, 0.4);
    }
</style>
<p>基于Centos7.9操作系统和Docker容器引擎，构建Ollama + Gradio+ Deepseek&#x2F;Qwen环境，搭建大模型本地知识库，可以为企业快速搭建本地知识库，构建企业管理的智能体，提升内部信息管理效率。</p>
<span id="more"></span>
<div class="note info"><p>🤔 <strong>写在前面：</strong> 转载自2025 ccf培训内容</p>
</div>

<h2 id="模块简介"><a href="#模块简介" class="headerlink" title="模块简介"></a>模块简介</h2><p>基于Centos7.9操作系统和Docker容器引擎，构建Ollama + Gradio+ Deepseek&#x2F;Qwen环境，搭建大模型本地知识库，可以为企业快速搭建本地知识库，构建企业管理的智能体，提升内部信息管理效率。</p>
<h2 id="模块知识"><a href="#模块知识" class="headerlink" title="模块知识"></a>模块知识</h2><p>（1）理解国产大模型（DeepSeek&#x2F;Qwen）的技术特点与应用场景；</p>
<p>（2）掌握 Ollama 实现大模型本地部署的核心原理；</p>
<p>（3）理解服务网格与声明式 API 在云原生架构中的作用；</p>
<p>（4）能独立完成 CentOS 环境下 Docker+Ollama 的离线部署；</p>
<p>（5）能通过 Dify 平台构建企业本地知识库与智能体应用；</p>
<p>（6）能使用 Gradio 开发大模型交互界面。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>使用线上平台提供的实验环境，准备一台CentOS 7.9操作系统的虚拟机，一台桌面化测试环境。实验节点的具体规划见表1。</p>
<p>表1 节点规划</p>
<table>
<thead>
<tr>
<th><strong>IP</strong></th>
<th><strong>主机名</strong></th>
<th><strong>节点</strong></th>
</tr>
</thead>
<tbody><tr>
<td>192.168.100.23</td>
<td>ollama</td>
<td>大模型节点</td>
</tr>
<tr>
<td>-</td>
<td>localhost</td>
<td>桌面化测试环境</td>
</tr>
</tbody></table>
<h2 id="模块内容"><a href="#模块内容" class="headerlink" title="模块内容"></a>模块内容</h2><h3 id="1-大模型平台介绍"><a href="#1-大模型平台介绍" class="headerlink" title="1. 大模型平台介绍"></a>1. 大模型平台介绍</h3><p>本项目通过构建Docker+Ollama + Gradio容器化环境，以构建一个企业本地知识库，实现助手智能体。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925568.jpg" alt="1"></p>
<p>图1 项目示意</p>
<h4 id="1-1-DeepSeek-Qwen国产大模型介绍"><a href="#1-1-DeepSeek-Qwen国产大模型介绍" class="headerlink" title="1.1 DeepSeek&#x2F;Qwen国产大模型介绍"></a><strong>1.1 DeepSeek&#x2F;Qwen国产大模型介绍</strong></h4><p>DeepSeek 的 AI 大模型是国产之光，千亿参数规模下，API 调用成本低至 0.5 元&#x2F;百万 tokens，中文基准测试得分高达 91.5%，推理效率还比传统架构提升了 5 倍。基于DeepSeek企业能轻松搭建本地知识库，提升信息管理效率。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925570.jpg" alt="2"></p>
<p>图2 DeepSeek产品</p>
<p>千问大模型堪称国产大模型领域的 “超级明星”。它有着千亿级别的参数规模，依托千问大模型，企业能够轻松搭建本地知识库。通过对企业内部各类文档、资料、数据的整合与分析，模型可以快速定位和提供准确信息，极大地提升企业信息管理效率，帮助员工快速获取所需知识，减少查找信息的时间成本，为企业决策提供有力的数据支持。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925571.png" alt="3"></p>
<p>图3 千问大模型</p>
<h4 id="1-2-Ollama：简化本地部署"><a href="#1-2-Ollama：简化本地部署" class="headerlink" title="1.2 Ollama：简化本地部署"></a>1.2 Ollama：简化本地部署</h4><p>Ollama 是一个开源的本地化工具，专门用来简化大型语言模型的本地运行和部署。它能让用户在个人计算机或服务器上轻松运行多种开源语言大模型，比如 DeepSeek、Qwen、Llama 等，完全不依赖云端服务，也不用复杂配置。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925572.jpg" alt="4"></p>
<p>图4 Ollama 开源的本地化工具</p>
<h4 id="1-3-Gradio可视化界面"><a href="#1-3-Gradio可视化界面" class="headerlink" title="1.3 Gradio可视化界面"></a>1.3 Gradio可视化界面</h4><p>Gradio是一个搭建可视化界面的Python库，也是一个强大且易用的工具，可以帮助开发者快速构建交互式的机器学习模型展示界面。它提供了一个简单易用的界面搭建框架，让用户可以很容易地将模型部署为一个交互式的Web应用程序，而无需编写任何前端代码。</p>
<p>Gradio支持各种类型的输入数据，包括文本、图像、音频和视频，让用户可以通过简单的拖放操作来测试和调整模型。用户可以自定义界面的样式和布局，添加各种控件来与模型交互，比如滑块、文本框、下拉菜单等。</p>
<p>通过Gradio，用户可以快速构建一个漂亮的Web应用程序，用于展示自己的机器学习模型，与其他人分享模型的功能和性能，或者用于实际的应用场景中。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925573.png" alt="5"></p>
<p>图5 Gradio可视化界面</p>
<h3 id="2-实战案例——搭建大模型平台"><a href="#2-实战案例——搭建大模型平台" class="headerlink" title="2. 实战案例——搭建大模型平台"></a>2. 实战案例——搭建大模型平台</h3><h4 id="2-1-Docker离线部署"><a href="#2-1-Docker离线部署" class="headerlink" title="2.1 Docker离线部署"></a>2.1 Docker离线部署</h4><p>下载docker-20.10.20.tgz、dify_images.tar.gz、models.tar.gz、dify-main.zip软件包，这些软件包分别用于安装Docker、Dify镜像导入、离线大模型导入Ollama管理平台和Dify容器化安装。将软件包下载到大模型节点上，并进行Docker服务的安装。</p>
<p>首先修改主机名，修改完成后点击左边工具栏的”重连”按钮，或者使用bash命令进行刷新：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@res-n18437027226-f2exsogjhi ~]# hostnamectl set-hostname ollama</span><br><span class="line">[root@res-n18437027226-f2exsogjhi ~]# bash</span><br></pre></td></tr></table></figure>

<p>开始下载软件包4个软件包：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/docker-20.10.20.tgz</span><br><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/dify_images.tar.gz</span><br><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/models.tar.gz</span><br><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/dify-main.zip</span><br></pre></td></tr></table></figure>

<p>开始安装Docker服务，先解压 Docker 二进制文件包，并且把解压得到的可执行文件复制到&#x2F;usr&#x2F;bin&#x2F;目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# tar zxvf docker-20.10.20.tgz </span><br><span class="line">[root@ollama ~]# cp -rfv docker/* /usr/bin/ </span><br></pre></td></tr></table></figure>

<p>创建一个 systemd 服务配置文件，其目的是将 Docker 作为系统服务进行管理。配置文件里定义了服务的描述、启动顺序、执行命令以及重启策略等内容。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# cat &gt;&gt; /usr/lib/systemd/system/docker.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>启动并启用 Docker 服务，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# systemctl daemon-reload &amp;&amp; systemctl restart docker &amp;&amp; systemctl enable docker </span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span><br></pre></td></tr></table></figure>

<p>配置 Docker 镜像加速和 cgroup 驱动，最后重新加载配置并重启 Docker，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# cat &gt;&gt;/etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://ebjpjftd.mirror.aliyuncs.com&quot;],</span><br><span class="line">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">[root@ollama ~]# systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br></pre></td></tr></table></figure>

<p>Docker 是一个开源的应用容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在本地编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925574.png" alt="6"></p>
<p>图6 Docker应用容器引擎</p>
<p>简单的理解，Docker类似于集装箱，各式各样的货物，经过集装箱的标准化进行托管，而集装箱和集装箱之间没有影响。也就是说，Docker平台就是一个软件集装箱化平台，这就意味着我们自己可以构建应用程序，将其依赖关系一起打包到一个容器中，然后这容器就很容易运送到其他的机器上进行运行，而且非常易于装载、复制、移除，非常适合软件弹性架构。</p>
<p>Docker提供容器管理的工具：</p>
<ul>
<li>Docker CLI（Command - Line Interface）：这是一个命令行工具，允许用户通过命令行输入来与 Docker 引擎进行交互。用户可以使用 CLI 来执行各种操作，如拉取镜像、创建容器、启动容器、查看容器状态等。</li>
<li>Docker Compose：用于定义和运行多容器 Docker 应用程序的工具。用户可以通过一个 YAML 文件来定义应用程序中的多个容器及其配置，包括容器之间的依赖关系、网络设置、卷挂载等。</li>
</ul>
<h4 id="2-2-Ollama大模型管理平台容器部署"><a href="#2-2-Ollama大模型管理平台容器部署" class="headerlink" title="2.2 Ollama大模型管理平台容器部署"></a>2.2 Ollama大模型管理平台容器部署</h4><p>（1）基于Docker进行Ollama部署</p>
<p>创建&#x2F;root&#x2F;ollama目录，导入Dify镜像：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# mkdir /root/ollama</span><br><span class="line">[root@ollama ~]# tar zxvf /root/dify_images.tar.gz</span><br><span class="line">[root@ollama ~]# cd /root/dify_images/ &amp;&amp; sh load.sh</span><br></pre></td></tr></table></figure>

<p>部署Ollama服务，返回结果如图7所示。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama dify_images]# cd /root/</span><br><span class="line">[root@ollama ~]# docker run -d -v /root/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama</span><br><span class="line">[root@ollama ~]# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE           COMMAND               CREATED              STATUS              PORTS                                           NAMES</span><br><span class="line">695d51a52a44   ollama/ollama   &quot;/bin/ollama serve&quot;   About a minute ago   Up About a minute   0.0.0.0:11434-&gt;11434/tcp, :::11434-&gt;11434/tcp   ollama</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925575.png" alt="7"></p>
<p>图7 Docker部署</p>
<p>正常运行后，可以登录网站进行查看Ollama的状态，如图8所示：</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925576.png" alt="8"></p>
<p>图8 查看Ollama的状态</p>
<p>（2）离线部署大模型</p>
<p>进入到Ollama模型存储目录，将打包好的models.tar.gz离线模型软件包解压到存储目录中，如图9所示，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# cd /root/ollama/</span><br><span class="line">[root@ollama ollama]# tar zxvf /root/models.tar.gz -C .</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925577.png" alt="9"></p>
<p>图9  解压models.tar.gz</p>
<p>解压完成后，进行验证，查看是否成功部署离线模型，如图10所示，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ollama]# docker exec -it ollama bash</span><br><span class="line">root@a049e8f3c525:/# ollama list</span><br><span class="line">NAME                ID              SIZE      MODIFIED     </span><br><span class="line">deepseek-r1:1.5b    a42b25d8c10a    1.1 GB    4 months ago    </span><br><span class="line">qwen:0.5b           b5dc5e784f2a    394 MB    4 months ago</span><br><span class="line">root@a049e8f3c525:/# exit</span><br></pre></td></tr></table></figure>

<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925578.png" alt="10" style="zoom:67%;" />

<p>图10 验证</p>
<p>可以看到，模型成功被导入到Ollama中。</p>
<h4 id="2-3-Dify-容器编排部署"><a href="#2-3-Dify-容器编排部署" class="headerlink" title="2.3 Dify 容器编排部署"></a>2.3 Dify 容器编排部署</h4><p>（1）安装 Dify 环境</p>
<p>首先需要配置Yum源仓库，安装依赖工具，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ollama]# rm -rf /etc/yum.repos.d/*</span><br><span class="line">[root@ollama ollama]# cat &gt;&gt; /etc/yum.repos.d/local.repo &lt;&lt;EOF</span><br><span class="line">[centos]</span><br><span class="line">name=centos</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">baseurl=http://mirrors.douxuedu.com/centos/</span><br><span class="line">EOF</span><br><span class="line">[root@ollama ollama]# yum install -y unzip</span><br></pre></td></tr></table></figure>

<p>将下载的dify-main.zip源码包解压，并进入到容器化安装目录，配置环境变量，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ollama]# cd /root/</span><br><span class="line">[root@ollama ~]# unzip dify-main.zip</span><br><span class="line">[root@ollama ~]# cd dify-main/docker/</span><br><span class="line">[root@ollama docker]# cp -rfv .env.example .env</span><br><span class="line">‘.env.example’ -&gt; ‘.env’</span><br></pre></td></tr></table></figure>

<p>进行容器化安装Dify，首先安装Docker Compose，并修改配置，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama docker]# curl -O http://mirrors.douxuedu.com/newcloud/docker-compose</span><br><span class="line">[root@ollama docker]# chmod +x docker-compose &amp;&amp;cp docker-compose /usr/bin/</span><br><span class="line">[root@ollama docker]# docker-compose --version</span><br><span class="line">Docker Compose version v2.33.1</span><br><span class="line">[root@llama docker]# vi /root/dify-main/docker/docker-compose.yaml</span><br></pre></td></tr></table></figure>

<p>修改以下配置，此配置在548行。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">plugin_daemon:</span><br><span class="line">  environment: #在此段里加入如下两行配置</span><br><span class="line">    PYTHON_ENV_INIT_TIMEOUT: 320 #添加此配置</span><br><span class="line">    PLUGIN_MAX_EXECUTION_TIMEOUT: 2400 #添加此配置</span><br></pre></td></tr></table></figure>

<p>完整内容如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">plugin_daemon:</span><br><span class="line">    image: langgenius/dify-plugin-daemon:0.0.3-local</span><br><span class="line">    restart: always</span><br><span class="line">    environment:</span><br><span class="line">      # Use the shared environment variables.</span><br><span class="line">      &lt;&lt;: *shared-api-worker-env</span><br><span class="line">      DB_DATABASE: $&#123;DB_PLUGIN_DATABASE:-dify_plugin&#125;</span><br><span class="line">      SERVER_PORT: $&#123;PLUGIN_DAEMON_PORT:-5002&#125;</span><br><span class="line">      SERVER_KEY: $&#123;PLUGIN_DAEMON_KEY:-lYkiYYT6owG+71oLerGzA7GXCgOT++6ovaezWAjpCjf+Sjc3ZtU+qUEi&#125;</span><br><span class="line">      MAX_PLUGIN_PACKAGE_SIZE: $&#123;PLUGIN_MAX_PACKAGE_SIZE:-52428800&#125;</span><br><span class="line">      PPROF_ENABLED: $&#123;PLUGIN_PPROF_ENABLED:-false&#125;</span><br><span class="line">      DIFY_INNER_API_URL: $&#123;PLUGIN_DIFY_INNER_API_URL:-http://api:5001&#125;</span><br><span class="line">      DIFY_INNER_API_KEY: $&#123;INNER_API_KEY_FOR_PLUGIN:-QaHbTe77CtuXmsfyhR7+vRjI/+XbV1AaFy691iy+kGDv2Jvy0/eAh8Y1&#125;</span><br><span class="line">      PLUGIN_REMOTE_INSTALLING_HOST: $&#123;EXPOSE_PLUGIN_DEBUGGING_HOST:-localhost&#125;</span><br><span class="line">      PLUGIN_REMOTE_INSTALLING_PORT: $&#123;EXPOSE_PLUGIN_DEBUGGING_PORT:-5003&#125;</span><br><span class="line">      PLUGIN_WORKING_PATH: $&#123;PLUGIN_WORKING_PATH:-/app/storage/cwd&#125;</span><br><span class="line">      FORCE_VERIFYING_SIGNATURE: $&#123;FORCE_VERIFYING_SIGNATURE:-true&#125;</span><br><span class="line">      PYTHON_ENV_INIT_TIMEOUT: 320 #新增加配置</span><br><span class="line">      PLUGIN_MAX_EXECUTION_TIMEOUT: 2400 #新增加配置</span><br></pre></td></tr></table></figure>

<p>最后启动Dify服务，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama docker]# docker-compose up -d</span><br><span class="line">[+] Running 12/12</span><br><span class="line"> ✔ Network docker_default             Created                                      0.1s </span><br><span class="line"> ✔ Network docker_ssrf_proxy_network  Created                                      0.0s </span><br><span class="line"> ✔ Container docker-web-1             Started                                      1.5s </span><br><span class="line"> ✔ Container docker-sandbox-1         Started                                      0.9s </span><br><span class="line"> ✔ Container docker-plugin_daemon-1   Started                                      1.1s </span><br><span class="line"> ✔ Container docker-db-1              Started                                      1.4s </span><br><span class="line"> ✔ Container docker-redis-1           Started                                      1.4s </span><br><span class="line"> ✔ Container docker-weaviate-1        Started                                      1.1s </span><br><span class="line"> ✔ Container docker-ssrf_proxy-1      Started                                      1.6s </span><br><span class="line"> ✔ Container docker-worker-1          Started                                      2.2s </span><br><span class="line"> ✔ Container docker-api-1             Started                                      2.2s </span><br><span class="line"> ✔ Container docker-nginx-1           Started                                      2.2s</span><br></pre></td></tr></table></figure>

<p>安装完成后，使用以下命令进行验证，检查状态是否为Up状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama docker]# docker-compose ps</span><br><span class="line">NAME                     IMAGE                                       COMMAND                  SERVICE         CREATED         STATUS                   PORTS</span><br><span class="line">docker-api-1             langgenius/dify-api:1.0.0                   &quot;/bin/bash /entrypoi…&quot;   api             6 minutes ago   Up 6 minutes             5001/tcp</span><br><span class="line">docker-db-1              postgres:15-alpine                          &quot;docker-entrypoint.s…&quot;   db              6 minutes ago   Up 6 minutes (healthy)   0.0.0.0:5432-&gt;5432/tcp, [::]</span><br><span class="line">:5432-&gt;5432/tcp</span><br><span class="line">docker-nginx-1           nginx:latest                                &quot;sh -c &#x27;cp /docker-e…&quot;   nginx           6 minutes ago   Up 6 minutes             0.0.0.0:80-&gt;80/tcp, [::]:80-</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">80/tcp, 0.0.0.0:443-&gt;443/tcp, [::]:443-&gt;443/tcp</span></span><br><span class="line">docker-plugin_daemon-1   langgenius/dify-plugin-daemon:0.0.3-local   &quot;/bin/bash -c /app/e…&quot;   plugin_daemon   6 minutes ago   Up 6 minutes             0.0.0.0:5003-&gt;5003/tcp, [::]</span><br><span class="line">:5003-&gt;5003/tcp</span><br><span class="line">docker-redis-1           redis:6-alpine                              &quot;docker-entrypoint.s…&quot;   redis           6 minutes ago   Up 6 minutes (healthy)   6379/tcp</span><br><span class="line">docker-sandbox-1         langgenius/dify-sandbox:0.2.10              &quot;/main&quot;                  sandbox         6 minutes ago   Up 6 minutes (healthy)   </span><br><span class="line">docker-ssrf_proxy-1      ubuntu/squid:latest                         &quot;sh -c &#x27;cp /docker-e…&quot;   ssrf_proxy      6 minutes ago   Up 6 minutes             3128/tcp</span><br><span class="line">docker-weaviate-1        semitechnologies/weaviate:1.19.0            &quot;/bin/weaviate --hos…&quot;   weaviate        6 minutes ago   Up 6 minutes             </span><br><span class="line">docker-web-1             langgenius/dify-web:1.0.0                   &quot;/bin/sh ./entrypoin…&quot;   web             6 minutes ago   Up 6 minutes             3000/tcp</span><br><span class="line">docker-worker-1          langgenius/dify-api:1.0.0                   &quot;/bin/bash /entrypoi…&quot;   worker          6 minutes ago   Up 6 minutes             5001/tcp</span><br></pre></td></tr></table></figure>

<p><strong>docker-web-1 (Web Frontend)</strong></p>
<ul>
<li><strong>功能：</strong> 这是 Dify 的用户界面（UI）。</li>
<li><strong>作用：</strong> 提供可视化操作界面，用户在此创建、管理、调试应用，配置提示词、数据集、模型，查看日志和分析数据等。通常基于 React 或 Vue 等前端框架构建。</li>
<li><strong>依赖：</strong> 与 <code>docker-api-1</code> 通信获取数据和执行操作。</li>
</ul>
<p><strong>docker-api-1(API Server)</strong></p>
<ul>
<li><strong>功能：</strong> 这是 Dify 的后端核心服务，提供 RESTful API。</li>
<li><strong>作用：</strong> 处理来自 Web 前端 (<code>web</code>) 和最终用户应用的请求。负责业务逻辑，如应用管理、数据集管理（文档处理、嵌入）、提示词工程、模型调用编排、日志记录、用户管理、计费等。</li>
<li><strong>依赖：</strong> 与数据库 (<code>db</code>)、缓存 (<code>redis</code>)、向量数据库 (<code>weaviate</code>)、模型提供方（如 OpenAI, Anthropic, 本地模型等）、工作队列 (<code>worker</code>) 进行交互。</li>
</ul>
<p><strong>docker-worker-1 (Celery Worker)</strong></p>
<ul>
<li><strong>功能：</strong> 异步任务处理引擎（通常基于 Celery）。</li>
<li><strong>作用：</strong> 处理耗时的后台任务，避免阻塞 API 服务器的响应。典型任务包括：<ul>
<li>长文本的拆分、清洗和嵌入到向量数据库（当上传数据集时）。</li>
<li>调用需要较长时间响应的模型（特别是开源大模型）。</li>
<li>生成报告、批量操作等。</li>
</ul>
</li>
<li><strong>依赖：</strong> 接收来自 <code>docker-api-1</code> 或定时触发的任务消息（通常通过 <code>redis</code> 作为消息代理），访问数据库 (<code>db</code>)、向量数据库 (<code>weaviate</code>)、模型提供方。</li>
</ul>
<p><strong>docker-db-1 (PostgreSQL Database)</strong></p>
<ul>
<li><strong>功能：</strong> 主关系型数据库（通常是 PostgreSQL）。</li>
<li><strong>作用：</strong> 持久化存储所有结构化数据，例如：<ul>
<li>用户账户信息、组织信息</li>
<li>应用配置（名称、图标、模型设置、提示词模板等）</li>
<li>数据集元数据（名称、状态、来源等）</li>
<li>对话历史记录、消息</li>
<li>日志（应用调用日志、错误日志）</li>
<li>插件配置</li>
</ul>
</li>
<li><strong>核心依赖：</strong> 被 <code>docker-api-1</code> 和 <code>docker-worker-1</code> 频繁读写。</li>
</ul>
<p><strong>docker-redis-1 (Redis Cache &amp; Message Broker)</strong></p>
<ul>
<li><strong>功能：</strong> 内存数据存储，用作缓存和消息代理。</li>
<li><strong>作用：</strong><ul>
<li><strong>缓存：</strong> 缓存频繁访问的数据（如模型配置、应用配置、临时状态），减轻数据库 (<code>db</code>) 压力，加速 API 响应。</li>
<li><strong>消息代理：</strong> 作为 Celery 的后端，在 <code>docker-api-1</code> 和 <code>docker-worker-1</code> 之间传递异步任务消息。</li>
<li><strong>会话存储&#x2F;临时数据：</strong> 可能用于存储用户会话信息或其他需要快速读写的临时数据。</li>
</ul>
</li>
<li><strong>核心依赖：</strong> <code>docker-api-1</code> 和 <code>docker-worker-1</code> 使用它进行缓存和任务队列通信。</li>
</ul>
<p><strong>docker-weaviate-1 (Weaviate Vector Database)</strong></p>
<ul>
<li><strong>功能：</strong> 向量数据库。</li>
<li><strong>作用：</strong> 专门用于存储和高效检索文本（或其他数据）的向量嵌入（embeddings）。这是实现 RAG（检索增强生成）功能的核心组件。<ul>
<li>当用户上传文档到数据集时，<code>worker</code> 会将文本块转换成向量并存入 Weaviate。</li>
<li>当用户提问时，API 会将问题转换成向量，在 Weaviate 中进行相似度搜索，找到最相关的文本片段，然后将这些片段作为上下文提供给 LLM 生成更准确、基于知识的回答。</li>
</ul>
</li>
<li><strong>依赖：</strong> 主要被 <code>docker-api-1</code> (执行检索) 和 <code>docker-worker-1</code> (执行嵌入和存储) 使用。</li>
</ul>
<p><strong>docker-plugin_daemon-1 (Plugin Daemon)</strong></p>
<ul>
<li><strong>功能：</strong> 插件管理守护进程（在早期版本中可能直接集成在 API 里）。</li>
<li><strong>作用：</strong> 负责加载、管理、执行和监控 Dify 平台上的插件。插件用于扩展平台功能，例如连接到外部 API（数据库查询）、执行特定工具（代码执行）、集成其他服务等。它确保插件的安全隔离（与 <code>sandbox</code> 相关）和稳定运行。</li>
<li><strong>依赖：</strong> 与 <code>docker-api-1</code> 通信（API 将需要插件执行的请求转发给它），可能调用 <code>docker-sandbox-1</code> 执行非受信插件代码。</li>
</ul>
<p><strong>docker-sandbox-1 (Sandbox Environment)</strong></p>
<ul>
<li><strong>功能：</strong> 代码执行沙箱（通常是基于 Firecracker 或 gVisor 的安全容器）。</li>
<li><strong>作用：</strong> 提供一个高度隔离、资源受限的环境，用于<strong>安全地执行不受信任的代码</strong>。主要用于：<ul>
<li>运行用户上传的<strong>自定义 Python 工具&#x2F;插件代码</strong>。</li>
<li>可能用于执行某些需要隔离处理的<strong>数据集预处理逻辑</strong>。</li>
</ul>
</li>
<li><strong>目的：</strong> 防止恶意或错误代码影响主平台（API、Worker、数据库等）的稳定性和安全性。是平台安全性的重要保障。</li>
<li><strong>依赖：</strong> 由 <code>docker-plugin_daemon-1</code> 或 <code>docker-worker-1</code> 触发执行特定代码任务。</li>
</ul>
<p><strong>docker-nginx-1 (Nginx Reverse Proxy)</strong></p>
<ul>
<li><strong>功能：</strong> Web 服务器和反向代理。</li>
<li><strong>作用：</strong><ul>
<li><strong>反向代理：</strong> 作为统一的入口点，接收外部（用户浏览器、客户端应用）的 HTTP&#x2F;HTTPS 请求，并根据路径规则将请求转发到内部对应的服务（主要是 <code>docker-web-1</code> 和 <code>docker-api-1</code>）。例如 <code>/</code> 转发到 Web UI， <code>/v1/</code> 转发到 API Server。</li>
<li><strong>负载均衡（如果有多实例）：</strong> 可以将请求分发到多个后端实例（虽然单机部署通常只有一个实例）。</li>
<li><strong>SSL&#x2F;TLS 终止：</strong> 处理 HTTPS 加密解密。</li>
<li><strong>静态文件服务：</strong> 可能直接提供 Web 前端的静态资源（JS, CSS, 图片）。</li>
<li><strong>基础路由和访问控制。</strong></li>
</ul>
</li>
<li><strong>核心依赖：</strong> 所有外部流量首先到达这里。它代理到 <code>docker-web-1</code> 和 <code>docker-api-1</code>。</li>
</ul>
<p><strong>docker-ssrf_proxy-1 (SSRF Proxy Service - 特定组件)</strong></p>
<ul>
<li><strong>功能：</strong> 一个专门设计用于防御 Server-Side Request Forgery (SSRF) 攻击的代理服务。</li>
<li><strong>作用：</strong> 当 Dify 平台上的某些功能（例如：网页抓取插件、从 URL 加载数据集、某些插件功能）需要代表服务器发起对外部网络资源的 HTTP&#x2F;HTTPS 请求时，这些请求会被强制路由通过这个 <code>ssrf_proxy</code> 服务。<ul>
<li><strong>安全控制：</strong> 该服务实施严格的安全策略，限制可以访问的目标主机、端口、协议（通常只允许 HTTP&#x2F;HTTPS 到常见端口），并过滤危险的请求头和响应内容（如私有 IP 地址、AWS&#x2F;GCP&#x2F;Azure 元数据服务地址 <code>169.254.169.254</code> 等）。</li>
<li><strong>目的：</strong> 防止攻击者通过精心构造的输入（如恶意 URL），诱使服务器内部组件访问其本不该访问的内部系统（如数据库管理接口、云元数据服务获取凭证、内网应用），从而造成严重安全风险。</li>
</ul>
</li>
<li><strong>依赖：</strong> 被需要安全发起外部网络请求的组件调用，通常是 <code>docker-worker-1</code> (处理数据集 URL 加载、网页抓取插件任务) 或 <code>docker-plugin_daemon-1</code> (执行需要网络访问的插件)。</li>
</ul>
<p>切换到桌面端机器，打开浏览器，输入<a href="http://ip/%EF%BC%8C%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AEDify%EF%BC%8C%E5%A6%82%E5%9B%BE11%E6%89%80%E7%A4%BA%E3%80%82">http://ip/，进行访问Dify，如图11所示。</a></p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925579.png" alt="11" style="zoom:67%;" />

<p>图11 访问Dify</p>
<p>设置管理员账号：填写邮箱、用户名、密码后，再重新登录一下，如图12和图13所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925580.png" alt="12" style="zoom:67%;" />

<p>图12 登录界面</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925581.png" alt="13"></p>
<p>图13 控制台界面</p>
<p>到此，Dify部署完成。</p>
<h4 id="2-4-安装Gradio框架"><a href="#2-4-安装Gradio框架" class="headerlink" title="2.4 安装Gradio框架"></a>2.4 安装Gradio框架</h4><p>因为Gradio是一个搭建可视化界面的Python库，所以首先需要有Python环境，此处是Python版本为Python3.7.3。安装Python开发环境以及Gradio框架。</p>
<p>首先下载并解压 Python 源码包，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama docker]# cd /root/</span><br><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/python3.7.3.tar.gz</span><br><span class="line">[root@ollama ~]# tar zxvf /root/python3.7.3.tar.gz -C /usr/local/</span><br></pre></td></tr></table></figure>

<p>创建全局软链接，使系统可以通过python3和pip3命令调用新安装的 Python 3.7.3 及其包管理器，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# ln -s /usr/local/python3/bin/python3.7 /usr/bin/python3</span><br><span class="line">[root@ollama ~]# ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip3</span><br></pre></td></tr></table></figure>

<p>最后验证Python版本和检查 Gradio 库是否安装成功：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# python3 --version</span><br><span class="line">python3.7.3</span><br><span class="line">[root@ollama ~]# pip3 list |grep gradio</span><br></pre></td></tr></table></figure>

<p>验证是否有Gradio框架包，如果查询出来，则表示无需安装。</p>
<p><strong>注意：本实验是连续实验，请不要释放实验环境。</strong></p>
<h3 id="3-实战案例——大模型平台应用"><a href="#3-实战案例——大模型平台应用" class="headerlink" title="3.  实战案例——大模型平台应用"></a>3.  实战案例——大模型平台应用</h3><h4 id="3-1-将本地大模型与-Dify-进行关联"><a href="#3-1-将本地大模型与-Dify-进行关联" class="headerlink" title="3.1 将本地大模型与 Dify 进行关联"></a>3.1 将本地大模型与 Dify 进行关联</h4><p>返回到Dify主界面，点击右上角用户名下的”设置”，如图14所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925582.png" alt="14"></p>
<p>图14 设置</p>
<p>选择“模型供应商”，找到对应的 Ollama，点击“安装”按钮，如图15所示。然后跳转对话框再次点击“安装”按钮，如图16所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925583.png" alt="15"></p>
<p>图15 点击“安装”</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925584.png" alt="16" style="zoom:67%;" />

<p>图16 安装插件</p>
<p>安装完成后，在“模型供应商”中找到Ollama插件，并点击“添加模型”，如图17所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925585.png" alt="17"></p>
<p>图17  添加模型</p>
<p>添加模型的信息，通过以下命令来查看：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@llama docker]# docker exec -it ollama  ollama list</span><br><span class="line">NAME                ID              SIZE      MODIFIED     </span><br><span class="line">deepseek-r1:1.5b    a42b25d8c10a    1.1 GB    3 months ago    </span><br><span class="line">qwen:0.5b           b5dc5e784f2a    394 MB    3 months ago</span><br></pre></td></tr></table></figure>

<p>填写模型对应的信息，然后点击“保存”按钮，如图18所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925586.png" alt="18" style="zoom: 50%;" />

<p>图18  填写模型对应的信息</p>
<p>保存过程中，插件容器会进行离线安装相关服务，在此期间可以通过以下命令来观察过程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama docker]# docker logs docker-plugin_daemon-1 -f</span><br></pre></td></tr></table></figure>

<p>如图19所示，在日志中看到此结果，则表示可以正常添加模型。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925587.png" alt="19"></p>
<p>图19 日志结果</p>
<p>Qwen模型按照同样步骤，添加成功后，如图20所示，可以看到两个模型已经加入到了Dify里。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925588.png" alt="20"></p>
<p>图20 模型添加成功</p>
<p>添加好模型后，接下来是设置系统模型，刷新网页。点击右上角用户名下的“设置”，选择“模型供应商”，点击右侧的“系统模型设置”，如图21所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925589.png" alt="21"></p>
<p>图21 系统模型设置</p>
<p>然后选择模型，点击“保存”，如图22所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925590.png" alt="22" style="zoom:80%;" />

<p>图22 选择模型</p>
<p>到此，Dify就与前面部署的本地大模型关联起来了。</p>
<h4 id="3-2-创建聊天助手智能体应用"><a href="#3-2-创建聊天助手智能体应用" class="headerlink" title="3.2 创建聊天助手智能体应用"></a>3.2 创建聊天助手智能体应用</h4><p>（1）创建空白应用</p>
<p>进入 Dify 主界面，点击“创建空白应用”，如图23所示：</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925591.png" alt="23"></p>
<p>图23 创建空白应用</p>
<p>选择“聊天助手”，输入自定义应用名称和描述，点击“创建”按钮，如图24所示。该调试界面如图25所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925592.png" alt="24"></p>
<p>图24 选择聊天助手</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925593.png" alt="25"></p>
<p>图25 调试与预览界面</p>
<h4 id="3-3-创建本地知识库"><a href="#3-3-创建本地知识库" class="headerlink" title="3.3 创建本地知识库"></a>3.3 创建本地知识库</h4><p>（1）添加Embedding 模型</p>
<p>Embedding模型可以把复杂的、高维的数据（比如文本、图像等）转换成低维的向量。这些向量虽然看起来只是数字，但它们能够很好地捕捉到数据的语义信息。</p>
<p>首先，它可以用于文本分类，比如判断一篇文章是正面评价还是负面评价；还可以用于相似性搜索，比如在海量的文本中快速找到和用户问题最相关的答案；甚至在推荐系统中，通过Embedding模型把用户和商品的特征转换成向量，就能更精准地给用户推荐他们可能喜欢的东西。</p>
<p>在搭建知识库的时候，我们上传的资料（比如文档、文章等）需要先通过Embedding模型转换成向量，然后存入向量数据库。这样，当有人提问的时候，系统就能通过自然语言理解问题，然后在向量数据库中快速、准确地找到相关的资料，从而给出准确的回答。所以，提前把私有数据向量化入库，是为了让知识库在回答问题时更高效、更准确。</p>
<p>点击右上角用户名下的“设置”，选择”模型供应商”，点击右侧的“添加模型”，如图26和图27所示：</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925594.png" alt="26" style="zoom:55%;" />

<p>图26 添加Ollama</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925595.png" alt="27"></p>
<p>图27 添加成功</p>
<p>（2）创建知识库</p>
<p>返回 Dify 主界面，点击上方的“知识库”，点击“创建知识库”，如图28所示。</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925596.png" alt="28"></p>
<p>图28 创建知识库</p>
<p>在桌面端使用浏览器登陆到<a href="http://mirrors.douxuedu.com/newcloud/%E6%AD%A4%E5%9C%B0%E5%9D%80%EF%BC%8C%E7%84%B6%E5%90%8E%E6%89%BE%E5%88%B0guicheng.docx%EF%BC%8C%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%EF%BC%8C%E4%B8%8B%E8%BD%BD%E5%88%B0%E6%A1%8C%E9%9D%A2%E7%AB%AF%E6%9C%BA%E5%99%A8%E3%80%82">http://mirrors.douxuedu.com/newcloud/此地址，然后找到guicheng.docx，点击下载，下载到桌面端机器。</a></p>
<p>如图29所示，选择“导入已有文本”，上传资料（支持 TXT、PDF、Word、Excel 等格式，比如：可以上传一份企业内部的项目文档，或者个人的学习笔记）。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925597.png" alt="29" style="zoom:60%;" />

<p>图29 导入已有文本</p>
<p>选择合适的模型，并配置相关参数后点击“保存并处理”，如图30和图31所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925598.png" alt="30" style="zoom:50%;" />

<p>图30 配置相关参数</p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925599.png" alt="31"></p>
<p>图31 保存并处理</p>
<p>耐心等待，系统会自动对上传的文档进行解析和向量化处理。这个过程可能需要几分钟，具体时间取决于文档的大小和复杂程度。完成后会出现“嵌入已完成”信息，如图32所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925600.png" alt="32" style="zoom: 67%;" />

<p>图32 嵌入已完成</p>
<p>创建成功后我们可以点击“前往文档”按钮，查看分段信息，如图33所示：</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925601.png" alt="33" style="zoom:75%;" />

<p>图33  查看分段信息</p>
<p>（3）为对话上下文添加知识库</p>
<p>返回 Dify 主界面，回到刚才的应用聊天页面，添加知识库，如图34所示：</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925602.png" alt="34" style="zoom:70%;" />

<p>图34 添加知识库</p>
<p>然后选择刚刚创建的知识库，如图35所示：</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925603.png" alt="35" style="zoom:60%;" />

<p>图35 选择知识库</p>
<p>选中后点击“添加”按钮，如图36所示：</p>
 <img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925604.png" alt="36" style="zoom:80%;" />

<p>图36 添加</p>
<p>选择刚才创建的知识库作为对话上下文。保存当前应用设置后，就可以测试了，如图37所示。</p>
<img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925605.png" alt="37" style="zoom:67%;" />

<p>图37  测试</p>
<p>以上得出，DeepSeek的思考过程非常有特点，感觉就像有一个认真负责的人在仔细翻阅文档。它会把自己查找和分析的过程展示得很清楚，最后给出一个严谨的结论。如果你有一个专门的学术知识库，它不仅能帮你查找信息，还能进行推理、思考和总结，使用起来非常方便。</p>
<p> <strong>注意：本实验是连续实验，请不要释放实验环境。</strong></p>
<h3 id="4-实战案例——大模型对接开发"><a href="#4-实战案例——大模型对接开发" class="headerlink" title="4.  实战案例——大模型对接开发"></a>4.  实战案例——大模型对接开发</h3><p>将完整的代码文件下载到大模型节点，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# curl -O http://mirrors.douxuedu.com/newcloud/chat.py</span><br></pre></td></tr></table></figure>

<p>基于Ollama模型管理和Gradio框架，可以快速搭建一个直观的聊天界面，代码名称为chat.py，查看该文件代码如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# cat chat.py </span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import gradio as gr</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义API的URL</span></span><br><span class="line">url = &quot;http://localhost:11434/api/generate&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义请求头，指定内容类型为JSON</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;Content-Type&#x27;: &#x27;application/json&#x27;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化对话历史列表</span></span><br><span class="line">conversation_history = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_response(prompt):</span><br><span class="line">    # 将用户输入的prompt添加到对话历史中</span><br><span class="line">    conversation_history.append(prompt)</span><br><span class="line"></span><br><span class="line">    # 将对话历史合并为一个完整的prompt</span><br><span class="line">    full_prompt = &quot;\n&quot;.join(conversation_history)</span><br><span class="line"></span><br><span class="line">    # 构建请求数据</span><br><span class="line">    data = &#123;</span><br><span class="line">        &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;, #在此处选择后端语言模型</span><br><span class="line">        &quot;stream&quot;: False,</span><br><span class="line">        &quot;prompt&quot;: full_prompt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    # 发送POST请求</span><br><span class="line">    response = requests.post(url, headers=headers, data=json.dumps(data))</span><br><span class="line"></span><br><span class="line">    # 检查响应状态码</span><br><span class="line">    if response.status_code == 200:</span><br><span class="line">        response_txt = response.text</span><br><span class="line">        data = json.loads(response_txt)</span><br><span class="line">        actual_response = data[&quot;response&quot;]</span><br><span class="line">        # 将模型的回复添加到对话历史中</span><br><span class="line">        conversation_history.append(actual_response)</span><br><span class="line">        return actual_response</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;Error:&quot;, response.status_code, response.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iface = gr.Interface(</span><br><span class="line">    fn=generate_response,</span><br><span class="line">    inputs=[&quot;text&quot;],</span><br><span class="line">    outputs=[&quot;text&quot;]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    iface.launch(server_name=&quot;0.0.0.0&quot;)</span><br></pre></td></tr></table></figure>

<p>使用以下命令运行代码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ollama ~]# python3 /root/chat.py</span><br></pre></td></tr></table></figure>

<p>在浏览器中，输入<a href="http://ip:7860/%E8%AE%BF%E9%97%AE%E9%A1%B5%E9%9D%A2%EF%BC%8C%E7%84%B6%E5%90%8E%E5%B0%9D%E8%AF%95%E5%9C%A8prompt%E4%B8%AD%E8%BE%93%E5%85%A5%E4%BF%A1%E6%81%AF%E8%BF%9B%E8%A1%8C%E8%AF%A2%E9%97%AE%E3%80%82%E4%BE%8B%E5%A6%82%E8%BE%93%E5%85%A5%E2%80%9C%E4%BD%A0%E6%98%AF%E8%B0%81%EF%BC%9F%E2%80%9D%E5%B9%B6%E6%8F%90%E4%BA%A4%EF%BC%8C%E5%9C%A8output%E4%B8%AD%E4%BC%9A%E6%98%BE%E7%A4%BA%E5%9B%9E%E7%AD%94%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%A6%82%E5%9B%BE38%E6%89%80%E7%A4%BA%E3%80%82">http://ip:7860/访问页面，然后尝试在prompt中输入信息进行询问。例如输入“你是谁？”并提交，在output中会显示回答信息，如图38所示。</a></p>
<p><img data-src="https://raw.githubusercontent.com/lanOAO/blog_img/main/202509071925606.png" alt="38"></p>
<p>图37 访问页面</p>
<h3 id="5-项目总结"><a href="#5-项目总结" class="headerlink" title="5.  项目总结"></a>5.  项目总结</h3><p>通过 Ollama + Gradio+ Deepseek这个组合，企业可以轻松搭建本地知识库，提升内部信息管理效率。无论是文档检索、问答系统还是自动化工作流，都能轻松搞定，行业典型应用如下：</p>
<p>（1）智能问答</p>
<p>系统通过集成DeepSeek和Qwen模型，实现了深度语言理解能力，能够准确捕捉用户问题的语义和意图。这种能力使得系统能够快速、准确地给出用户所需答案，无论问题涉及业务咨询、技术问题还是日常交流。这种深度语言理解与智能问答的紧密融合，显著提升了用户体验和系统的实用性。</p>
<p>（2）对话记录分析</p>
<p>系统具备对话记录与分析功能，能够记录用户的对话历史，并对其进行深入分析。通过挖掘用户的需求和行为模式，系统能够更好地了解用户，从而提供更加个性化的服务和建议。这种功能不仅提升了用户体验，还为系统的持续优化和改进提供了数据支持。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>ccf</tag>
        <tag>dify</tag>
        <tag>Centos</tag>
        <tag>Gradio</tag>
        <tag>Ollama</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机相关记录</title>
    <url>/LanBlog/computer_reference.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="c5a9d62a158a50279128f62e9d3043275bb00b63d9aeb0226bccdc819029d65f">13892574096ed43c3d9bcdc076d901838387543c7371061ca519d260b8163f1e3957df996a2c81e5d776a83c6e427c4935e11da00bfaabc8c54996410a580b821f4847905b7942c3946a73a4178b5de2164ace3a09b1594cc3c09e34a93ff62e1c11cf0c092f0db666a432ba4def4e225ea222b6fbde7fdfbef2ef1a7fdca1b3d57e2aa95cbf5d42e6488d7e871947bc5151f795778077a417ba5273c5b172b6ddf0359af29d0c728333da6e08649fc2411ce87deace1e72cd897fee62961d34417dcf5194601af72524dd0899a2e0d65bfd5abd6eff47a88327e83e7a877b37b719c1433dad30e2e0a3e8eaf71456d9204def87f402eb10f81dfa1ba632107a01a7876e259e523ffa56ed7b23591f60973fe0e0c86d6871b52b63c195d7ca1a184ff6178a08e320cdeb3e55b4c44e6f36d8f4a5555624f98478702fc6817435c38fc76db6160564d38420e6faebc035abce4b1bb5336322c469874b0fb3a915a07804ef8291d0f259387a7ab65721a8bc16398d503f6af4947bed3c146079a424ec26a60c33ae2b70b89263e4cf943728b02be13042f3deb9310b936c52b97a34a5d4e6c9e14b6f6373d210d0a41e492127f99a35493667d03e4d401b74727336bbf262c2bda87acb2a5a425847b00a1a52fd094343fe76ce171c347d04d5dfc46a82c0b0cb500a3760d9861c927951bd23724a0d4596d8597c22708605d0c0d14feaeb2c3053f37d0d4beb22d2ca022717f4cc8b09693bb48c7fea55ac407cdb4a0beeaf4ece4ae24ea03ec2f6b13e3ffcb865c88a07fb2427f4a33666de88852281678b051dfb1b8efad7527cdd33fdb6338602fff323c2d5770bc99bb82bed313efe6a37ae7d26d84abeef9d96fe4c0844ab2cc9a27065aa773f515c02d8d68d43565788d2d1485b14684ec886e38965607ce2968f8173ae07a094166c27b02e5c4c0cf67b540dd464b5f2f21cf0ca8a8b6f95ddf9a648482b673f144cb0a6047d7bf8729127066af02988c5b95212edce480b6a2700975aa7ba1c1f1fc3caf3040911c3cf380a9d64381fdaaebccf6e41087ef8c9c3ebd553693218654f58dd38ce017655d37d9781967609031983bae10d6899ae7cc173e75e89a34693653bdb897bc28304c99d149752c02ca71cda2d9379539e35bf8163ea766855499b9833bb8081483296cb09ed29d3e2a2975a7d113f1f8fb917e5e2576ddba469</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-xray">
      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">您好, 这里需要密码.</span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/LanBlog/lib/hbe.js"></script><link href="/LanBlog/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>QWQ</tag>
      </tags>
  </entry>
  <entry>
    <title>各种各样的参考页面</title>
    <url>/LanBlog/reference.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="29b02275861e51fbd16b1b0992fde67cc0fec4af07be429550b7f65950d1d032">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-xray">
      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">您好, 这里需要密码.</span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/LanBlog/lib/hbe.js"></script><link href="/LanBlog/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>参考</tag>
      </tags>
  </entry>
</search>
